{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d8a3fc76-e7b9-4600-88d8-b637f74424f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import(\n",
    "    classification_report, accuracy_score, roc_auc_score, RocCurveDisplay, PrecisionRecallDisplay\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b701e495-220e-40b2-a616-b867c309e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6e88b1d7-e886-45d0-a358-d1d5f3863c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_dataset(filepath):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"LOAD AND  EXPLORE DATASET\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(\"Shape of the dataset\")\n",
    "    print(df.shape)\n",
    "    print(\"\\nCheck for missing values\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\nFirst five rows:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nDescriptive stats\")\n",
    "    print(df.describe())\n",
    "    print(\"\\nDataset Info\")\n",
    "    print(df.info())\n",
    "    print(\"\\nChurn Status Distribution:\")\n",
    "    print(df[\"Churn Value\"].value_counts())\n",
    "    print(\"\\nChurn Status percentage Distribution:\")\n",
    "    print(df[\"Churn Value\"].value_counts(normalize=True) * 100)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1c78a140-0c8f-410a-9704-c433cee7d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_features(df):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"IDENTIFY FEATURE DATASET\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    numerical_features = [\n",
    "        \"Senior Citizen\",\n",
    "        \"Partner\",\n",
    "        \"Dependents\",\n",
    "        \"Tenure Months\",\n",
    "        \"Phone Service\",\n",
    "        \"Multiple Lines\",\n",
    "        \"Total Internet Services\",\n",
    "        \"Total Charges\",\n",
    "    ]\n",
    "\n",
    "    categorical_features = [\n",
    "        \"City\",\n",
    "        \"Gender\",\n",
    "        \"Internet Service\",\n",
    "        \"Contract\",\n",
    "        \"Payment Method\",    \n",
    "    ]\n",
    "\n",
    "    print(\"\\nNumerical features :\", numerical_features)\n",
    "    print(\"Categirical features :\", categorical_features)\n",
    "\n",
    "    return numerical_features, categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6e0b8e8f-996c-4124-8c52-c1c8ecbeedf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, numerical_features, categorical_features):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PREPARE DATASET\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    target_column = \"Churn Value\"\n",
    "\n",
    "    X = df[numerical_features + categorical_features]\n",
    "    y = df[target_column]\n",
    "\n",
    "    print(\"\\nFeature shape:\", X.shape)\n",
    "    print(\"\\nTarget shape :\", y.shape)\n",
    "    print(\"\\nFeature columns list:\", list(X.columns))\n",
    "\n",
    "    return X, y, list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "078360fa-06dd-4ffc-b449-8e8cfbd1bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SPLITING DATA INTO TEST/TRAIN\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    print(\"\\nTraining set size\", X_train.shape[0])\n",
    "    print(\"Testing set size\", X_test.shape[0])\n",
    "    print(\"Train medical status distribution\", y_train.value_counts())\n",
    "    print(\"Test medical status distribution\", y_test.value_counts())\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f3317f66-338b-4fb1-be2f-6cea0d3c4502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_pipeline(numerical_features, categorical_features):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CREATING MODEL PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "    categorical_transformer = Pipeline(steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numerical_transformer, numerical_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"randomforestrclassifier\", RandomForestClassifier( n_estimators=100, max_depth=35, min_samples_split=5,\n",
    "        min_samples_leaf=2, random_state=42, n_jobs=1))\n",
    "    ])\n",
    "\n",
    "    # model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nModel created successfully\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7c2ee94c-313b-4d33-8c04-b83ffb2f4ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model_pipeline(numerical_features, categorical_features):\n",
    "#     print(\"\\n\" + \"=\" * 60)\n",
    "#     print(\"CREATING MODEL PIPELINE\")\n",
    "#     print(\"=\" * 60)\n",
    "\n",
    "#     # numerical features pipeline\n",
    "#     numerical_pipeline = Pipeline([\n",
    "#         (\"scaler\", StandardScaler())\n",
    "#     ])\n",
    "\n",
    "#     # categorical features pipeline\n",
    "#     categorical_pipeline = Pipeline([\n",
    "#         (\"onehot\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))\n",
    "#     ])\n",
    "\n",
    "#     # column preprocesing\n",
    "#     preprocessor = ColumnTransformer([\n",
    "#         (\"num\", numerical_pipeline, numerical_features),\n",
    "#         (\"cat\", categorical_pipeline, categorical_features)\n",
    "#     ])\n",
    "    \n",
    "\n",
    "#     model = Pipeline([\n",
    "#         (\"preprocessor\", preprocessor),\n",
    "#         (\"classifier\", LogisticRegression(\n",
    "#             max_iter= 1000,\n",
    "#             random_state=42,\n",
    "#             class_weight=\"balanced\",\n",
    "#             solver=\"lbfgs\"\n",
    "#         ))\n",
    "#         # (\"decisiontree\", DecisionTreeClassifier(max_depth=6, random_state=42))\n",
    "#     ])\n",
    "\n",
    "#     print(\"\\nModel created successfully\")\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "83501cbd-bd01-412a-b60f-0eeac38cad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TRAINING MODEL\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nModel train successfully\")\n",
    "\n",
    "    #get name steps preprocessing\n",
    "    try:\n",
    "        # Get preprocessor\n",
    "        preprocessor = model.named_steps[\"preprocessor\"]\n",
    "\n",
    "        # Get feature names automatically\n",
    "        feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "        # Get coefficients\n",
    "        classifier = model.named_steps[\"classifier\"]\n",
    "        coefficients = classifier.coef_[0]\n",
    "        # tree_model = model.steps[-1][1]\n",
    "        # importances = tree_model.feature_importances_\n",
    "        \n",
    "\n",
    "        feature_importance = (\n",
    "            pd.DataFrame({\n",
    "                \"feature\": feature_names,\n",
    "                # \"importance\": importances\n",
    "                \"coefficient\": coefficients\n",
    "            })\n",
    "            .sort_values(\"coefficient\", key=abs, ascending=False)\n",
    "        )\n",
    "\n",
    "        print(\"\\nTop 10 Most Important Features:\")\n",
    "        print(feature_importance.head(10).to_string(index=False))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not extract feature names: {e}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "709c0e9d-65a0-4961-81be-b083f7431516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"EVALUATING MODEL\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    #predicted model\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # predicted model prob\n",
    "    y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "    y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # metrics\n",
    "    y_train_acc_score = accuracy_score(y_train, y_train_pred)\n",
    "    y_test_acc_score = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    y_train_roc_score = roc_auc_score(y_train, y_train_proba)\n",
    "    y_test_roc_score = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "    print(\"\\nMETRICS EVALUATION\")\n",
    "    print(f\"\\nTrain accuracy score:, {float(y_train_acc_score):.4f}\")\n",
    "    print(f\"\\nTest accuracy score:, {float(y_test_acc_score):.4f}\")\n",
    "    print(f\"\\nTrain ROC score:, {float(y_train_roc_score):.4f}\")\n",
    "    print(f\"\\nTest ROC score:, {float(y_test_roc_score):.4f}\")\n",
    "\n",
    "    print(\"\\nCLASSIFICATION OF TRAIN SIZE\")\n",
    "    print(\"\\nclassificatin report\\n\", classification_report(y_train, y_train_pred, target_names=[\"Negative\", \"positive\"]))\n",
    "\n",
    "    print(\"\\nCLASSIFICATION OF TRAIN SIZE\")\n",
    "    print(\"\\nclassificatin report\\n\", classification_report(y_test, y_test_pred, target_names=[\"Negative\", \"Positive\"]))\n",
    "\n",
    "    # cross validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"roc_auc\")\n",
    "    print(\"\\nCross Validation (5-folds)\")\n",
    "    print(f\" R2 scores: {cv_scores}\")\n",
    "    print(f\" Cross validation mean: {cv_scores.mean():.4f}\")\n",
    "    print(f\" Cross validation STD: {cv_scores.std():.4f}\")\n",
    "\n",
    "    metrics = {\n",
    "        \"y_train_acc_score\":  y_train_acc_score,\n",
    "        \"y_test_acc_score\": y_test_acc_score,\n",
    "        \"y_train_roc_score\": y_train_roc_score,\n",
    "        \"y_test_roc_score\": y_test_roc_score,\n",
    "        \"y_train_pred\":  y_train_pred,\n",
    "        \"y_test_pred\": y_test_pred,\n",
    "        \"y_train_proba\": y_train_proba,\n",
    "        \"y_test_proba\": y_test_proba,\n",
    "        \"cv_scores\": cv_scores \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c628f29e-68c9-4ccb-8d38-f93e1f64701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOAD AND  EXPLORE DATASET\n",
      "============================================================\n",
      "Shape of the dataset\n",
      "(7032, 14)\n",
      "\n",
      "Check for missing values\n",
      "City                       0\n",
      "Gender                     0\n",
      "Senior Citizen             0\n",
      "Partner                    0\n",
      "Dependents                 0\n",
      "Tenure Months              0\n",
      "Phone Service              0\n",
      "Multiple Lines             0\n",
      "Internet Service           0\n",
      "Total Internet Services    0\n",
      "Contract                   0\n",
      "Payment Method             0\n",
      "Total Charges              0\n",
      "Churn Value                0\n",
      "dtype: int64\n",
      "\n",
      "First five rows:\n",
      "          City  Gender  Senior Citizen  Partner  Dependents  Tenure Months  \\\n",
      "0  Los Angeles    Male               0        0           0              2   \n",
      "1  Los Angeles  Female               0        0           1              2   \n",
      "2  Los Angeles  Female               0        0           1              8   \n",
      "3  Los Angeles  Female               0        1           1             28   \n",
      "4  Los Angeles    Male               0        0           1             49   \n",
      "\n",
      "   Phone Service  Multiple Lines Internet Service  Total Internet Services  \\\n",
      "0              1               0              DSL                        2   \n",
      "1              1               0      Fiber optic                        0   \n",
      "2              1               1      Fiber optic                        3   \n",
      "3              1               1      Fiber optic                        4   \n",
      "4              1               1      Fiber optic                        4   \n",
      "\n",
      "         Contract             Payment Method  Total Charges  Churn Value  \n",
      "0  Month-to-month               Mailed check         108.15            1  \n",
      "1  Month-to-month           Electronic check         151.65            1  \n",
      "2  Month-to-month           Electronic check         820.50            1  \n",
      "3  Month-to-month           Electronic check        3046.05            1  \n",
      "4  Month-to-month  Bank transfer (automatic)        5036.30            1  \n",
      "\n",
      "Descriptive stats\n",
      "       Senior Citizen      Partner   Dependents  Tenure Months  Phone Service  \\\n",
      "count     7032.000000  7032.000000  7032.000000    7032.000000    7032.000000   \n",
      "mean         0.162400     0.482509     0.230375      32.421786       0.903299   \n",
      "std          0.368844     0.499729     0.421103      24.545260       0.295571   \n",
      "min          0.000000     0.000000     0.000000       1.000000       0.000000   \n",
      "25%          0.000000     0.000000     0.000000       9.000000       1.000000   \n",
      "50%          0.000000     0.000000     0.000000      29.000000       1.000000   \n",
      "75%          0.000000     1.000000     0.000000      55.000000       1.000000   \n",
      "max          1.000000     1.000000     1.000000      72.000000       1.000000   \n",
      "\n",
      "       Multiple Lines  Total Internet Services  Total Charges  Churn Value  \n",
      "count     7032.000000              7032.000000    7032.000000  7032.000000  \n",
      "mean         0.421928                 2.038111    2283.300441     0.265785  \n",
      "std          0.493902                 1.847161    2266.771362     0.441782  \n",
      "min          0.000000                 0.000000      18.800000     0.000000  \n",
      "25%          0.000000                 0.000000     401.450000     0.000000  \n",
      "50%          0.000000                 2.000000    1397.475000     0.000000  \n",
      "75%          1.000000                 3.000000    3794.737500     1.000000  \n",
      "max          1.000000                 6.000000    8684.800000     1.000000  \n",
      "\n",
      "Dataset Info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7032 entries, 0 to 7031\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   City                     7032 non-null   object \n",
      " 1   Gender                   7032 non-null   object \n",
      " 2   Senior Citizen           7032 non-null   int64  \n",
      " 3   Partner                  7032 non-null   int64  \n",
      " 4   Dependents               7032 non-null   int64  \n",
      " 5   Tenure Months            7032 non-null   int64  \n",
      " 6   Phone Service            7032 non-null   int64  \n",
      " 7   Multiple Lines           7032 non-null   int64  \n",
      " 8   Internet Service         7032 non-null   object \n",
      " 9   Total Internet Services  7032 non-null   int64  \n",
      " 10  Contract                 7032 non-null   object \n",
      " 11  Payment Method           7032 non-null   object \n",
      " 12  Total Charges            7032 non-null   float64\n",
      " 13  Churn Value              7032 non-null   int64  \n",
      "dtypes: float64(1), int64(8), object(5)\n",
      "memory usage: 769.3+ KB\n",
      "None\n",
      "\n",
      "Churn Status Distribution:\n",
      "Churn Value\n",
      "0    5163\n",
      "1    1869\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Churn Status percentage Distribution:\n",
      "Churn Value\n",
      "0    73.421502\n",
      "1    26.578498\n",
      "Name: proportion, dtype: float64\n",
      "============================================================\n",
      "IDENTIFY FEATURE DATASET\n",
      "============================================================\n",
      "\n",
      "Numerical features : ['Senior Citizen', 'Partner', 'Dependents', 'Tenure Months', 'Phone Service', 'Multiple Lines', 'Total Internet Services', 'Total Charges']\n",
      "Categirical features : ['City', 'Gender', 'Internet Service', 'Contract', 'Payment Method']\n",
      "============================================================\n",
      "PREPARE DATASET\n",
      "============================================================\n",
      "\n",
      "Feature shape: (7032, 13)\n",
      "\n",
      "Target shape : (7032,)\n",
      "\n",
      "Feature columns list: ['Senior Citizen', 'Partner', 'Dependents', 'Tenure Months', 'Phone Service', 'Multiple Lines', 'Total Internet Services', 'Total Charges', 'City', 'Gender', 'Internet Service', 'Contract', 'Payment Method']\n",
      "\n",
      "============================================================\n",
      "SPLITING DATA INTO TEST/TRAIN\n",
      "============================================================\n",
      "\n",
      "Training set size 5625\n",
      "Testing set size 1407\n",
      "Train medical status distribution Churn Value\n",
      "0    4130\n",
      "1    1495\n",
      "Name: count, dtype: int64\n",
      "Test medical status distribution Churn Value\n",
      "0    1033\n",
      "1     374\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "CREATING MODEL PIPELINE\n",
      "============================================================\n",
      "\n",
      "Model created successfully\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL\n",
      "============================================================\n",
      "\n",
      "Model train successfully\n",
      "Could not extract feature names: 'classifier'\n",
      "\n",
      "============================================================\n",
      "EVALUATING MODEL\n",
      "============================================================\n",
      "\n",
      "METRICS EVALUATION\n",
      "\n",
      "Train accuracy score:, 0.8117\n",
      "\n",
      "Test accuracy score:, 0.7910\n",
      "\n",
      "Train ROC score:, 0.8783\n",
      "\n",
      "Test ROC score:, 0.8367\n",
      "\n",
      "CLASSIFICATION OF TRAIN SIZE\n",
      "\n",
      "classificatin report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.82      0.95      0.88      4130\n",
      "    positive       0.77      0.42      0.54      1495\n",
      "\n",
      "    accuracy                           0.81      5625\n",
      "   macro avg       0.79      0.69      0.71      5625\n",
      "weighted avg       0.81      0.81      0.79      5625\n",
      "\n",
      "\n",
      "CLASSIFICATION OF TRAIN SIZE\n",
      "\n",
      "classificatin report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.81      0.94      0.87      1033\n",
      "    Positive       0.69      0.38      0.49       374\n",
      "\n",
      "    accuracy                           0.79      1407\n",
      "   macro avg       0.75      0.66      0.68      1407\n",
      "weighted avg       0.78      0.79      0.77      1407\n",
      "\n",
      "\n",
      "Cross Validation (5-folds)\n",
      " R2 scores: [0.84575097 0.8802627  0.850958   0.82016933 0.85664078]\n",
      " Cross validation mean: 0.8508\n",
      " Cross validation STD: 0.0193\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    filepath = \"../data/cleaned/model_telco_customer_churn.csv\"\n",
    "    \n",
    "    df = load_and_explore_dataset(filepath)\n",
    "\n",
    "    numerical_features, categorical_features = identify_features(df)\n",
    "\n",
    "    X, y, feature_columns = prepare_data(df, numerical_features, categorical_features)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "    model = create_model_pipeline(numerical_features, categorical_features)\n",
    "\n",
    "    model = train_model(model, X_train, y_train)\n",
    "\n",
    "    metrics = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # precision_display, curve_display = visual_eval(model, X_test, y_test)\n",
    "\n",
    "#     save_model_artifact(model, feature_columns)\n",
    "\n",
    "#     # result = predict_status(patient_data)\n",
    "\n",
    "#     test_predict()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ff9f6-ab71-4a8b-9b15-f420a38baf8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
